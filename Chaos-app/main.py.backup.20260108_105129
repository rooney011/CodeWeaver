import logging
import sys
from datetime import datetime
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from fastapi.responses import FileResponse
from pathlib import Path
import requests

# Initialize FastAPI app
app = FastAPI(title="Chaos App", version="1.0.0")

# Enable CORS for Next.js dashboard
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Allow all origins for Docker networking
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Mount static files directory
static_dir = Path(__file__).parent / "static"
app.mount("/static", StaticFiles(directory=str(static_dir)), name="static")

# Global state variables
BROKEN_MODE = False
MEMORY_LEAK_MODE = False
LATENCY_MODE = False
CASCADE_MODE = False
ALERT_SENT = False  # Track if alert was already sent for this incident

# Configure logging to write to both file and stdout
log_dir = Path("/var/log/chaos-app")
log_file = log_dir / "service.log"

# Create log directory if it doesn't exist (for local development)
log_dir.mkdir(parents=True, exist_ok=True)

# Configure logger with immediate flushing
logger = logging.getLogger("chaos-app")
logger.setLevel(logging.INFO)

# File handler with immediate flush (no buffering)
file_handler = logging.FileHandler(log_file, mode='a', encoding='utf-8')
file_handler.setLevel(logging.INFO)
file_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s', 
                                   datefmt='%Y-%m-%d %H:%M:%S')
file_handler.setFormatter(file_formatter)
# Force immediate flush after every log
file_handler.flush = lambda: file_handler.stream.flush()

# Console handler (stdout) with immediate flush
console_handler = logging.StreamHandler(sys.stdout)
console_handler.setLevel(logging.INFO)
console_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s',
                                     datefmt='%Y-%m-%d %H:%M:%S')
console_handler.setFormatter(console_formatter)

# Add handlers to logger
logger.addHandler(file_handler)
logger.addHandler(console_handler)

# Ensure Python doesn't buffer stdout
sys.stdout.reconfigure(line_buffering=True) if hasattr(sys.stdout, 'reconfigure') else None


@app.get("/")
async def root():
    """Serve the E-Commerce frontend"""
    return FileResponse(static_dir / "index.html")


@app.get("/health")
async def health_check():
    """Health check endpoint"""
    return {"status": "running"}


# --- REAL BUGGY CODE (Agent will patch these) ---

# BUGGY: No timeout or retry logic
def connect_to_database():
    """Attempts to connect to the database"""
    import socket
    # BUG: No timeout, will hang indefinitely on connection issues
    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    sock.connect(('192.168.1.55', 5432))  # Non-existent DB
    return sock

# BUGGY: Unbounded cache causes memory leak
payment_cache = {}  # BUG: No size limit, grows indefinitely

def cache_payment(transaction_id, data):
    """Cache payment data"""
    # BUG: Cache never evicts old entries
    payment_cache[transaction_id] = data
    
# BUGGY: Synchronous call with no timeout
def call_payment_gateway():
    """Calls external payment service"""
    import socket
    # BUG: No timeout on external service call
    sock = socket.socket()
    sock.connect(('payment-gateway.example.com', 443))
    return sock

# --- SIMULATED INTERNAL MODULES FOR CASCADE FAILURE ---
def db_query():
    """Simulates a database query"""
    # This is the bottom of the stack trace
    raise ConnectionError("Connection refused to Primary DB")

def service_layer_process():
    """Simulates business logic layer"""
    # Calls the DB layer
    try:
        db_query()
    except Exception as e:
        raise RuntimeError(f"Service layer failed to process transaction: {e}")

def main_controller_action():
    """Simulates the main controller"""
    # Calls the service layer
    service_layer_process()
# --------------------------------------------------------



@app.get("/buy")
async def buy_endpoint():
    """
    Payment endpoint that simulates database connectivity issues when BROKEN_MODE is True
    """
    global BROKEN_MODE, MEMORY_LEAK_MODE, LATENCY_MODE, CASCADE_MODE, ALERT_SENT
    
    # 1. LATENCY CHECK
    if LATENCY_MODE:
        import time
        logger.warning("High latency detected in payment gateway...")
        # Flush immediately
        for handler in logger.handlers:
            handler.flush()
        
        # Determine if we should alert yet
        if not ALERT_SENT:
            ALERT_SENT = True
            logger.error("TIMEOUT: Payment gateway response time exceeded 5000ms")
            # Auto-alert logic could be reused here or simpler:
            await send_alert("Latency Spike", "critical", "TIMEOUT: Payment gateway response time exceeded 5000ms")
            
        time.sleep(5) # Artificial delay
        return {"status": "payment_success", "latency": "5002ms", "note": "High Latency"}

    # 2. MEMORY LEAK CHECK
    if MEMORY_LEAK_MODE:
        # ACTUALLY CALL THE BUGGY CACHE FUNCTION
        import uuid
        # Fill up the unbounded cache
        for i in range(1000):
            cache_payment(str(uuid.uuid4()), {"amount": 100, "user": f"user_{i}"})
        
        logger.warning(f"Memory usage critical: cache size = {len(payment_cache)} entries")
        logger.warning("payment_cache has no eviction policy - memory leak detected")
        for handler in logger.handlers:
            handler.flush()
            
        if not ALERT_SENT:
            ALERT_SENT = True
            error_msg = f"MemoryError: Unbounded cache at {len(payment_cache)} entries. No eviction policy in cache_payment()"
            logger.critical(error_msg)
            await send_alert("Memory Exhaustion", "critical", error_msg)
            
        raise HTTPException(status_code=500, detail="Internal Server Error: MemoryLimitExceeded")

    # 3. CASCADE FAILURE CHECK
    if CASCADE_MODE:
        try:
            main_controller_action()
        except Exception as e:
            # We want to log the FULL stack trace to show multi-file context
            import traceback
            error_msg = f"Cascade Failure: {str(e)}"
            
            # Log the full traceback which mentions main.py, service.py (simulated), etc.
            # In a real app these would be real files. 
            # checks: we are in main.py, so stack trace will show main.py. 
            # To illustrate multi-file better, we might need actual separate files, 
            # but for now we simulate function calls in this file which is valid stack trace too.
            # "File 'main.py', line X in service_layer_process" is what we'll get.
            
            tb_str = "".join(traceback.format_exc())
            logger.error(f"Transaction Failed.\n{tb_str}")
            
            if not ALERT_SENT:
                ALERT_SENT = True
                await send_alert("Cascade System Failure", "critical", error_msg)
                
            raise HTTPException(status_code=500, detail="Internal Server Error: CascadeFailure")

    # 4. STANDARD BROKEN MODE (DB Connection)
    if BROKEN_MODE:
        # ACTUALLY CALL THE BUGGY FUNCTION
        try:
            db_connection = connect_to_database()  # This will timeout/fail
        except Exception as e:
            # Log with explicit traceback
            import traceback
            tb_str = traceback.format_exc()
            
            # Log the actual error with file/line info
            error_msg = f"ConnectionError: {str(e)}"
            logger.error(error_msg)
            logger.error(f"Error in File: main.py, Line: 89, Function: connect_to_database()")
            logger.error(f"Stack trace:\n{tb_str}")
            
            # Force immediate flush to file
            for handler in logger.handlers:
                handler.flush()
            
            # Log additional critical error about service failure
            logger.critical("Service creates 500 error on endpoint /buy")
            for handler in logger.handlers:
                handler.flush()
                
            # AUTO-ALERT
            if not ALERT_SENT:
                ALERT_SENT = True
                await send_alert("Database Connection Failed", "critical", error_msg)
            
            # Raise HTTP 500 error
            raise HTTPException(status_code=500, detail="Internal Server Error")
        
    logger.info("Payment processed successfully")
    return {"status": "payment_success", "latency": "10ms"}


async def send_alert(title, severity, message):
    """Helper to send webhook to agent"""
    try:
        # URL for agent inside Docker network
        agent_url = "http://codeweaver-agent:8001/webhook/alert"
        payload = {
            "data": {
                "source": "chaos-app",
                "severity": severity,
                "message": message,
                "timestamp": datetime.now().isoformat(),
                "log_path": "/logs/service.log"
            }
        }
        # Use longer timeout (LLM processing can take time)
        # However, we prefer fire-and-forget or async processing on the agent side 
        # But here we just need to ensure the request is sent.
        requests.post(agent_url, json=payload, timeout=5.0)
        logger.info(f"Sent automatic alert to SRE Agent: {title}")
    except Exception as e:
        logger.error(f"Failed to auto-alert agent: {str(e)}")
        # CRITICAL FIX: If alert fails, allow retry!
        # Otherwise the system stays broken but silent forever.
        global ALERT_SENT
        ALERT_SENT = False


@app.post("/chaos/trigger")
async def trigger_chaos():
    """Trigger standard broken mode"""
    global BROKEN_MODE, ALERT_SENT, MEMORY_LEAK_MODE, LATENCY_MODE, CASCADE_MODE
    BROKEN_MODE = True
    MEMORY_LEAK_MODE = False
    LATENCY_MODE = False
    CASCADE_MODE = False
    ALERT_SENT = False
    logger.warning("CHAOS MODE ACTIVATED - DB Connection will fail")
    return {"status": "chaos_started", "mode": "broken_db"}

@app.post("/chaos/trigger/memory")
async def trigger_memory():
    """Trigger memory leak mode"""
    global BROKEN_MODE, ALERT_SENT, MEMORY_LEAK_MODE, LATENCY_MODE, CASCADE_MODE
    MEMORY_LEAK_MODE = True
    BROKEN_MODE = False
    LATENCY_MODE = False
    CASCADE_MODE = False
    ALERT_SENT = False
    logger.warning("CHAOS MODE ACTIVATED - Memory Leaking...")
    return {"status": "chaos_started", "mode": "memory_leak"}

@app.post("/chaos/trigger/latency")
async def trigger_latency():
    """Trigger latency mode"""
    global BROKEN_MODE, ALERT_SENT, MEMORY_LEAK_MODE, LATENCY_MODE, CASCADE_MODE
    LATENCY_MODE = True
    BROKEN_MODE = False
    MEMORY_LEAK_MODE = False
    CASCADE_MODE = False
    ALERT_SENT = False
    logger.warning("CHAOS MODE ACTIVATED - Latency increasing...")
    return {"status": "chaos_started", "mode": "latency"}

@app.post("/chaos/trigger/cascade")
async def trigger_cascade():
    """Trigger cascade failure mode"""
    global BROKEN_MODE, ALERT_SENT, MEMORY_LEAK_MODE, LATENCY_MODE, CASCADE_MODE
    CASCADE_MODE = True
    BROKEN_MODE = False
    MEMORY_LEAK_MODE = False
    LATENCY_MODE = False
    ALERT_SENT = False
    logger.warning("CHAOS MODE ACTIVATED - Cascade Failure imminent")
    return {"status": "chaos_started", "mode": "cascade"}

@app.post("/chaos/resolve")
async def resolve_chaos():
    """Resolve all chaos modes"""
    global BROKEN_MODE, ALERT_SENT, MEMORY_LEAK_MODE, LATENCY_MODE, CASCADE_MODE
    BROKEN_MODE = False
    MEMORY_LEAK_MODE = False
    LATENCY_MODE = False
    CASCADE_MODE = False
    ALERT_SENT = False
    logger.info("CHAOS MODE RESOLVED - System restored")
    return {"status": "recovered"}


@app.get("/status")
async def get_status():
    """Get current service status"""
    mode = "healthy"
    if BROKEN_MODE: mode = "broken_db"
    elif MEMORY_LEAK_MODE: mode = "memory_leak"
    elif LATENCY_MODE: mode = "latency"
    elif CASCADE_MODE: mode = "cascade"
    
    return {
        "status": "degraded" if mode != "healthy" else "healthy",
        "mode": mode
    }
